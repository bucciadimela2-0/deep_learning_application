# deep_learning_application

Laboratory repository for the Deep Learning Applications course, featuring hands-on experiments across Computer Vision, Natural Language Processing, and Adversarial Machine Learning domains.


## :test_tube: Lab1 - Convolutional Neural Networks
The first laboratory studies MLP degradation patterns and vanishing gradients across different activation functions and regularization techniques. It then compares standard CNNs against versions with skip connections, demonstrating how residual connections solve the degradation problem. Finally, Grad-CAM analysis is applied to the best model on both clean and adversarially perturbed images to reveal attention pattern changes under attack conditions.
> **Experimental Results**: All experiments and training metrics are tracked and visualized at: [wandb](https://wandb.ai/martina-buccioni98-unifi/deep-learning-application?nw=nwusermartinabuccioni98)

<details>
<summary>Let's break the ice with MLP </summary>
Among all the experiments conducted to study MLPs, two caught my attention. The first one focuses on the vanishing gradient problem in MLPs (to be fair, without any type of regularization). The second one, instead, focuses on normalizations.
<div align="center">
<img src="plots/mlp_activation_function.png" alt="Training Loss by Activation Function" width="400"/>
<img src="plots/normalizzazione.png" alt="Validation Loss by Regularization Method" width="400"/>
<p><em>Left: Training loss comparison across activation functions | Right: Validation loss for different regularization strategies</em></p>
</div>
</details>


## :test_tube: Lab3 - Transformers and NLP
<details>




</details>


## :test_tube: Lab4 - Adversarial Learning and Out Of Distribution
<details>
<summary></summary>



</details>
